{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONHEEkTjC9XY"
   },
   "source": [
    "# Assignment 3 Part 1A Introduction: Multi-label Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45145,
     "status": "ok",
     "timestamp": 1616954561158,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "YqYDcF5MEA81",
    "outputId": "8f29b6c1-0a82-4dc4-9136-9fb9c9ca4d84"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1616954666689,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "5GSsaDn6EJqv",
    "outputId": "bb07a110-d9ef-4b3c-a6d7-258d29a58eac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME_DIR = os.getcwd()\n",
    "print(HOME_DIR)\n",
    "# PWD = os.path.join(HOME_DIR, 'gdrive', 'MyDrive', 'Colab Notebooks', 'CS498', 'assignment3_part1')\n",
    "# os.listdir()\n",
    "# import os\n",
    "# os.chdir(\"/content/gdrive/My Drive/CS498DL/assignment3_part1\")\n",
    "# os.chdir(PWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1616955818957,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "PDfi7dTcDVSW"
   },
   "outputs": [],
   "source": [
    "# !chmod u+rwx download_data.sh\n",
    "# !./download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 14327,
     "status": "ok",
     "timestamp": 1616959928114,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "wKre6_DqUJjL",
    "outputId": "473bb61c-25dc-4d9f-ccfc-996002e5c26a"
   },
   "outputs": [],
   "source": [
    "shutil.copyfile(\"VOCtrainval_06-Nov-2007.tar\", \"/content/VOCtrainval_06-Nov-2007.tar\")\n",
    "!tar -xf \"/content/VOCtrainval_06-Nov-2007.tar\" -C \"/content/\" \n",
    "shutil.move(\"/content/VOCdevkit/\", \"/content/VOCdevkit_2007\")\n",
    "\n",
    "shutil.copyfile(\"VOCtest_06-Nov-2007.tar\", \"/content/VOCtest_06-Nov-2007.tar\")\n",
    "!tar -xf \"/content/VOCtest_06-Nov-2007.tar\" -C \"/content/\" \n",
    "shutil.move(\"/content/VOCdevkit/VOC2007\", \"/content/VOCdevkit_2007/VOC2007test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1616959795398,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "SwANgdPgC9Xe",
    "outputId": "d84a0417-ecb4-441f-f32b-087793ba4912"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import shutil\n",
    "\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import average_precision_score\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_submission import output_submission_csv\n",
    "from classifier import SimpleClassifier, Classifier#, AlexNet\n",
    "from voc_dataloader import VocDataset, VOC_CLASSES\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-LGmvTCC9Xe"
   },
   "source": [
    "# Multi-label Classification\n",
    "In this assignment, you train a classifier to do multi-label classificaton on the PASCAL VOC 2007 dataset. The dataset has 20 different class which can appear in any given image. Your classifier will predict whether each class appears in an image. This task is slightly different from exclusive multiclass classification like the ImageNet competition where only a single most appropriate class is predicted for an image.\n",
    "\n",
    "## Part 1A\n",
    "You will use this notebook to warm up with pytorch and the code+dataset that we will use for assignment3. \n",
    "\n",
    "### What to do\n",
    "In part 1A, You are asked to run below experiments. You don't need to change hyperparameters for this Part 1A's experiments. (the following code provides everything that you will need.)\n",
    "1. to train a simple network (defined in ```classifiers.py```) \n",
    "2. to train the AlexNet (PyTorch built-in) \n",
    "    - from scratch \n",
    "    - finetuning AlexNet pretrained on ImageNet\n",
    "\n",
    "\n",
    "    \n",
    "### What to submit\n",
    "We ask you to run the following code and report the results in your homework submission. You may want to leverage this part 1A get yourself familiar with PyTorch.\n",
    "\n",
    "You will the need the numbers and plots this notebook outputs for reports, but you are not required to submit this notebook as a printed pdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqmk9so8C9Xf"
   },
   "source": [
    "## Reading Pascal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3T9CvgfC9Xf"
   },
   "source": [
    "### Loading Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIcgtlyWC9Xf"
   },
   "source": [
    "In the following cell we will load the training data and also apply some transforms to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1616956380505,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "sKIV_C_UC9Xg"
   },
   "outputs": [],
   "source": [
    "# Transforms applied to the training data\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std= [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1616959956477,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "RHD41egEC9Xg",
    "outputId": "bfd431e9-be9f-4020-c7f6-c83610926242"
   },
   "outputs": [],
   "source": [
    "ds_train = VocDataset('/content/VOCdevkit_2007/VOC2007/','train',train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5NOQ8qHC9Xg"
   },
   "source": [
    "### Loading Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOWjWEyIC9Xg"
   },
   "source": [
    "We will load the test data for the PASCAL VOC 2007 dataset. Do __NOT__ add data augmentation transforms to validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1616956519399,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "DIxxrprnC9Xh"
   },
   "outputs": [],
   "source": [
    "# Transforms applied to the testing data\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1616959964462,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "WL_P6zkvC9Xh",
    "outputId": "711d9546-42f2-48cf-83a2-2ea96c705873"
   },
   "outputs": [],
   "source": [
    "ds_val = VocDataset('/content/VOCdevkit_2007/VOC2007/','val',test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6nZMKABC9Xh"
   },
   "source": [
    "### Visualizing the Data\n",
    "\n",
    "PASCAL VOC has bounding box annotations in addition to class labels. Use the following code to visualize some random examples and corresponding annotations from the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1PcEJL0_OA1Db2i2R334yQAcYEyyUxPR4"
    },
    "executionInfo": {
     "elapsed": 3830,
     "status": "ok",
     "timestamp": 1616959971284,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "Iidv_fP1C9Xh",
    "outputId": "d9047739-72e2-4089-af3d-f7f5570ffa2e"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(ds_train.names)+1)\n",
    "    _imgpath = os.path.join('VOCdevkit_2007/VOC2007/', 'JPEGImages', ds_train.names[idx]+'.jpg')\n",
    "    img = Image.open(_imgpath).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for j in range(len(ds_train.box_indices[idx])):\n",
    "        obj = ds_train.box_indices[idx][j]\n",
    "        draw.rectangle(list(obj), outline=(255,0,0))\n",
    "        draw.text(list(obj[0:2]), ds_train.classes[ds_train.label_order[idx][j]], fill=(0,255,0))\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(np.array(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9hkQ_z6C9Xj"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1616956627741,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "J7zDBvL0C9Xj"
   },
   "outputs": [],
   "source": [
    "# declare what device to use: gpu/cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1616956943159,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "W_VCIYrWJNnX",
    "outputId": "76b32df9-eb80-4da2-8832-4eb7e22901e5"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1616959983964,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "hYoUSl1OC9Xj"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1616959984835,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "_daqe6sCC9Xj"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1616956965566,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "1SFJEw7fC9Xj"
   },
   "outputs": [],
   "source": [
    "def train_classifier(train_loader, classifier, criterion, optimizer):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    return torch.stack(losses).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1616957206181,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "7ambvTo2C9Xk"
   },
   "outputs": [],
   "source": [
    "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        y_true = np.zeros((0,21))\n",
    "        y_score = np.zeros((0,21))\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = classifier(images)\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
    "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "        aps = []\n",
    "        # ignore first class which is background\n",
    "        for i in range(1, y_true.shape[1]):\n",
    "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "            if print_ind_classes:\n",
    "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
    "            aps.append(ap)\n",
    "        \n",
    "        mAP = np.mean(aps)\n",
    "        test_loss = np.mean(losses)\n",
    "        if print_total:\n",
    "            print('mAP: {0:.4f}'.format(mAP))\n",
    "            print('Avg loss: {}'.format(test_loss))\n",
    "        \n",
    "    return mAP, test_loss, aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1616957810832,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "asXqmIbGC9Xk"
   },
   "outputs": [],
   "source": [
    "# plot functions\n",
    "def plot_losses(train, val, test_frequency, num_epochs):\n",
    "    plt.plot(train, label=\"train\")\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"Loss Plot\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mAP(train, val, test_frequency, num_epochs):\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, train, label=\"train\")\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"mAP Plot\")\n",
    "    plt.ylabel(\"mAP\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V2Tozb7C9Xl"
   },
   "source": [
    "## Training the network \n",
    "\n",
    "The simple network you are given as is will allow you to reach around 0.15-0.2 mAP. In this project, you will find ways to design a better network. Save plots and final test mAP scores as you will be adding these to the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1616957877678,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "DptANTueC9Xl"
   },
   "outputs": [],
   "source": [
    "def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n",
    "    train_losses = []\n",
    "    train_mAPs = []\n",
    "    val_losses = []\n",
    "    val_mAPs = []\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        print(\"Starting epoch number \" + str(epoch))\n",
    "        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
    "        if(epoch%test_frequency==0 or epoch==1):\n",
    "            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n",
    "            train_mAPs.append(mAP_train)\n",
    "            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
    "            print('Evaluating classifier')\n",
    "            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
    "            val_losses.append(val_loss)\n",
    "            val_mAPs.append(mAP_val)\n",
    "    \n",
    "    return classifier, train_losses, val_losses, train_mAPs, val_mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10724,
     "status": "ok",
     "timestamp": 1616957905307,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "_2_HDzXYC9Xl"
   },
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier().to(device)\n",
    "# You can can use this function to reload a network you have already saved previously\n",
    "#classifier.load_state_dict(torch.load('voc_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1616958450703,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "3YuksF4rC9Xm"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 560202,
     "status": "ok",
     "timestamp": 1616960558267,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "5qW3TklAC9Xm",
    "outputId": "5a39ce0e-2416-4f8e-8149-b7fe92549a56"
   },
   "outputs": [],
   "source": [
    "# Training the Classifier\n",
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1616960561525,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "fdghFAzTC9Xm",
    "outputId": "c1c41f8c-b1cb-4bb8-d1e8-d5a5b96888a0"
   },
   "outputs": [],
   "source": [
    "# Compare train and validation metrics\n",
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1616960586616,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "eQPxdAlRC9Xm"
   },
   "outputs": [],
   "source": [
    "# Save the clssifier network\n",
    "# Suggestion: you can save checkpoints of your network during training and reload them later\n",
    "torch.save(classifier.state_dict(), './voc_simple_classifier_second_snapshot.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWNmG_YaC9Xm"
   },
   "source": [
    "# Evaluate on test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38083,
     "status": "ok",
     "timestamp": 1616960667050,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "fMN_tQlHC9Xn",
    "outputId": "60b80632-d776-4d43-f6d6-02a498892f5a"
   },
   "outputs": [],
   "source": [
    "ds_test = VocDataset('/content/VOCdevkit_2007/VOC2007test/','test', test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
    "                                               batch_size=50, \n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1)\n",
    "\n",
    "# Transforms applied to the testing data\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1616960671520,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "ovhvlwKgC9Xn"
   },
   "outputs": [],
   "source": [
    "output_submission_csv('my_solution.csv', test_aps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_X1K-KkC9Xn"
   },
   "source": [
    "# AlexNet Baselines (From Scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6r0krYZC9Xn"
   },
   "source": [
    "AlexNet was one of the earliest deep learning models to have success in classification. In this section we will be running classification with AlexNet as a baseline. Furthermore, we will run an ImageNet-pretrained AlexNet to observe the impact of well-trained features. Save plots and final test mAP scores as you will be adding these to the writeup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--X07v3cC9Xo"
   },
   "source": [
    "## Running AlexNet\n",
    "\n",
    "In this section, we train AlexNet from scratch using the same hyperparameters as our previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1616960691582,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "mWZKRs1NC9Xo"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "# Change classifier to AlexNet\n",
    "classifier = torchvision.models.alexnet(pretrained=False)\n",
    "classifier.classifier._modules['6'] = nn.Linear(4096, 21)   \n",
    "classifier = classifier.to(device)\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577564,
     "status": "ok",
     "timestamp": 1616961272125,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "T1Bd06yqC9Xo",
    "outputId": "dc3a357d-f133-4051-a599-e0501199762b"
   },
   "outputs": [],
   "source": [
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1616961299674,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "mlC5SRoJC9Xo",
    "outputId": "82c1a647-0cb8-4151-b4ef-9db02ec3d307"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37977,
     "status": "ok",
     "timestamp": 1616961397748,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "6I3wi0UkC9Xo",
    "outputId": "4c74e7a7-26da-4a62-e984-2b35c58e5a05"
   },
   "outputs": [],
   "source": [
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
    "print(\"Test mAP: \", mAP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1874,
     "status": "ok",
     "timestamp": 1616961547876,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "DZcfrewUatbA"
   },
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), './voc_alexnet_nopretrain_sgd_snapshot.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vME7vmxC9Xo"
   },
   "source": [
    "You should notice somewhat poor performance. You could try running AlexNet with an Adam optimizer instead with learning rate 1e-4 to see if that makes a difference. This experiment is not required for the writeup, but it may show you the importance of a good learning rate and optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgefd8ADC9Xo"
   },
   "source": [
    "## Pretrained AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbkGxRXEC9Xp"
   },
   "source": [
    "Here we look at the impact of pretrained features. This model's weights were trained on ImageNet, which is a much larger dataset. How do pretrained features perform on VOC? Why do you think there is such a large difference in performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "3cfb31345b484cb7af30d733bba08980",
      "b182270145df4e8cb2c5f2a5a5cbc6f0",
      "b024124a2e4a46ffb9d76b3517775977",
      "02baa0b296aa4b3e9a2d5fb76b1b73cc",
      "bdc0d8f9ad8844f29b50b961b2a83398",
      "645398ab2b464640bc74975c719441ec",
      "6f3b1afb1cb64ccb9ac9e0f23c84a420",
      "df48af6418eb43969ab354fde8428a62"
     ]
    },
    "executionInfo": {
     "elapsed": 8607,
     "status": "ok",
     "timestamp": 1616961569363,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "QOwZmbkcC9Xp",
    "outputId": "e6166317-8bd3-411f-96c9-ed6d7242135b"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "test_frequency = 5\n",
    "\n",
    "# Load Pretrained AlexNet\n",
    "classifier = torchvision.models.alexnet(pretrained=True)\n",
    "classifier.classifier._modules['6'] = nn.Linear(4096, 21)   \n",
    "classifier = classifier.to(device)\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 592977,
     "status": "ok",
     "timestamp": 1616962168023,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "mmRap7PJC9Xp",
    "outputId": "16c95362-4cfa-4c45-b349-53188353f400"
   },
   "outputs": [],
   "source": [
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1616962220206,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "jy54VEc9C9Xp",
    "outputId": "62b8f1c3-8e48-45aa-bf4f-f7edffdaf7ab"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39702,
     "status": "ok",
     "timestamp": 1616962261408,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "2SP1t2xzC9Xp",
    "outputId": "d39d7373-be86-4f24-8946-7ee3c04f621b"
   },
   "outputs": [],
   "source": [
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
    "print(\"Test mAP: \", mAP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1581,
     "status": "ok",
     "timestamp": 1616962266141,
     "user": {
      "displayName": "Tejaswin Parthasarathy",
      "photoUrl": "",
      "userId": "09598575916527773543"
     },
     "user_tz": 300
    },
    "id": "2qOu4N61C9Xp"
   },
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), './voc_alexnet_pretrain_sgd_snapshot.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDybKTCedh2y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MP3_P1A_Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02baa0b296aa4b3e9a2d5fb76b1b73cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df48af6418eb43969ab354fde8428a62",
      "placeholder": "​",
      "style": "IPY_MODEL_6f3b1afb1cb64ccb9ac9e0f23c84a420",
      "value": " 233M/233M [02:26&lt;00:00, 1.67MB/s]"
     }
    },
    "3cfb31345b484cb7af30d733bba08980": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b024124a2e4a46ffb9d76b3517775977",
       "IPY_MODEL_02baa0b296aa4b3e9a2d5fb76b1b73cc"
      ],
      "layout": "IPY_MODEL_b182270145df4e8cb2c5f2a5a5cbc6f0"
     }
    },
    "645398ab2b464640bc74975c719441ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f3b1afb1cb64ccb9ac9e0f23c84a420": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b024124a2e4a46ffb9d76b3517775977": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_645398ab2b464640bc74975c719441ec",
      "max": 244418560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bdc0d8f9ad8844f29b50b961b2a83398",
      "value": 244418560
     }
    },
    "b182270145df4e8cb2c5f2a5a5cbc6f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdc0d8f9ad8844f29b50b961b2a83398": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "df48af6418eb43969ab354fde8428a62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
